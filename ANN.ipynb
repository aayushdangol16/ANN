{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-MDhpSJ06Gf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import DataLoader,random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "zuB9CruY1DMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def leaky_relu(z):\n",
        "  return torch.where(z>0,z,0.01*z)"
      ],
      "metadata": {
        "id": "omb4cFtZ1f9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "JrlJITot1Enf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(train_data))\n",
        "val_size = len(train_data) - train_size\n",
        "train_subset, val_subset = random_split(train_data, [train_size, val_size])"
      ],
      "metadata": {
        "id": "iGWVcwvp1HRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_subset, batch_size=300, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=300, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=300, shuffle=False)"
      ],
      "metadata": {
        "id": "2WfX_uPD1JAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter=iter(train_loader)\n",
        "x_train,y_train=next(train_iter)\n",
        "x_train=torch.flatten(x_train,2).squeeze(1)"
      ],
      "metadata": {
        "id": "X_2tGLx31Lmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nhidden1=128\n",
        "nhidden2=64\n",
        "noutput=10"
      ],
      "metadata": {
        "id": "gn-Kg7BW1Qxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1=torch.randn(x_train.shape[1],nhidden1)*0.01\n",
        "w1.requires_grad_(True)\n",
        "b1=torch.zeros(1,nhidden1)\n",
        "b1.requires_grad_(True)\n",
        "\n",
        "w2=torch.randn(nhidden1,nhidden2)*0.01\n",
        "w2.requires_grad_(True)\n",
        "b2=torch.zeros(1,nhidden2)\n",
        "b2.requires_grad_(True)\n",
        "\n",
        "w3=torch.randn(nhidden2,noutput)*0.01\n",
        "w3.requires_grad_(True)\n",
        "b3=torch.zeros(1,noutput)\n",
        "b3.requires_grad_(True)\n",
        "\n",
        "\n",
        "gamma1=torch.ones(nhidden1)\n",
        "gamma1.requires_grad_(True)\n",
        "beta1=torch.zeros(nhidden1)\n",
        "beta1.requires_grad_(True)\n",
        "\n",
        "gamma2=torch.ones(nhidden2)\n",
        "gamma2.requires_grad_(True)\n",
        "beta2=torch.zeros(nhidden2)\n",
        "beta2.requires_grad_(True)\n",
        "\n",
        "dropout=0.5\n",
        "alpha=0.01"
      ],
      "metadata": {
        "id": "coHd-A5B1XEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st layer\n",
        "z1=x_train@w1+b1\n",
        "# 1st batch normalization\n",
        "mean1=z1.mean(0,keepdim=True)\n",
        "diff1=z1-mean1\n",
        "diff1_sqr=diff1**2.0\n",
        "diff1_sqr_mean=diff1_sqr.mean(0,keepdim=True)\n",
        "std1=torch.sqrt(diff1_sqr_mean)\n",
        "std1_inv=std1**-1.0\n",
        "batchnorm1=diff1*std1_inv\n",
        "batchout1=gamma1*batchnorm1+beta1\n",
        "# 1st activation\n",
        "leaky1=leaky_relu(batchout1)\n",
        "# 1st dropout\n",
        "mask1 = torch.bernoulli(torch.full_like(leaky1, 1 - dropout))\n",
        "output1 = (mask1 * leaky1) / (1 - dropout)\n",
        "\n",
        "# 2nd layer\n",
        "z2=output1@w2+b2\n",
        "# 2nd batch normalization\n",
        "mean2=z2.mean(0,keepdim=True)\n",
        "diff2=z2-mean2\n",
        "diff2_sqr=diff2**2.0\n",
        "diff2_sqr_mean=diff2_sqr.mean(0,keepdim=True)\n",
        "std2=torch.sqrt(diff2_sqr_mean)\n",
        "std2_inv=std2**-1.0\n",
        "batchnorm2=diff2*std2_inv\n",
        "batchout2=gamma2*batchnorm2+beta2\n",
        "# 2nd activation\n",
        "leaky2=leaky_relu(batchout2)\n",
        "# 2nd dropout\n",
        "mask2 = torch.bernoulli(torch.full_like(leaky2, 1 - dropout))\n",
        "output2 = (mask2 * leaky2) / (1 - dropout)\n",
        "\n",
        "# output layer\n",
        "z3=output2@w3+b3\n",
        "z3_max=z3.max(1,keepdim=True).values\n",
        "norm_z3=z3-z3_max\n",
        "exp_z3=torch.exp(norm_z3)\n",
        "exp_sum=(exp_z3.sum(dim=1,keepdim=True))\n",
        "exp_sum_inv=exp_sum**-1\n",
        "probs=exp_z3*exp_sum_inv\n",
        "logprobs=torch.log(probs)\n",
        "loss=-logprobs[range(len(x_train)),y_train].mean()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "w1.grad=None\n",
        "b1.grad=None\n",
        "w2.grad=None\n",
        "b2.grad=None\n",
        "for i in [batchout1,output2,output1,batchout2,batchnorm2,std2_inv,std2,diff2_sqr_mean,diff2_sqr,diff2,mean2,batchnorm1,std1_inv,std1,diff1_sqr_mean,diff1_sqr,diff1,mean1,z1,leaky1,z2,leaky2,z3,z3_max,norm_z3,exp_z3,exp_sum,probs,logprobs,exp_sum_inv]:\n",
        "  i.retain_grad()\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "QMvRI5Zi1vXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs=torch.zeros_like(logprobs)\n",
        "dlogprobs[range(len(x_train)),y_train]=-1.0/len(x_train)\n",
        "dprobs=(1.0/probs)*dlogprobs\n",
        "dexp_sum_inv=(exp_z3*dprobs).sum(1,keepdim=True)\n",
        "dexp_z3=exp_sum_inv*dprobs\n",
        "dexp_sum=(-exp_sum**-2)*dexp_sum_inv\n",
        "dexp_z3+=torch.ones_like(exp_z3)*dexp_sum\n",
        "dnorm_z3=torch.exp(norm_z3)*dexp_z3\n",
        "dz3=dnorm_z3.clone()\n",
        "dz3_max=(-dnorm_z3).sum(1,keepdim=True)\n",
        "dz3+=torch.nn.functional.one_hot(z3.max(1).indices,num_classes=z3.shape[1])*dz3_max\n",
        "dw3=output2.T@dz3\n",
        "db3=dz3.sum(0,keepdim=True)\n",
        "doutput2=dz3@w3.T\n",
        "\n",
        "dleaky2=(doutput2*mask2)/ (1 - dropout)\n",
        "dbatchout2=torch.where(batchout2>0,1,0.01)*dleaky2\n",
        "dgamma2=(batchnorm2*dbatchout2).sum(0,keepdim=True)\n",
        "dbeta2=dbatchout2.sum(0,keepdim=True)\n",
        "dbatchnorm2=gamma2*dbatchout2\n",
        "dstd2_inv=(diff2*dbatchnorm2).sum(0,keepdim=True)\n",
        "ddiff2=std2_inv*dbatchnorm2\n",
        "dstd2=-1.0*(std2**-2.0)*dstd2_inv\n",
        "ddiff2_sqr_mean=0.5*(diff2_sqr_mean**-0.5)*dstd2\n",
        "ddiff2_sqr=torch.ones_like(diff2_sqr)*ddiff2_sqr_mean/z2.shape[0]\n",
        "ddiff2+=2*diff2*ddiff2_sqr\n",
        "dz2=ddiff2.clone()\n",
        "dmean2=-ddiff2.sum(0,keepdim=True)\n",
        "dz2+=torch.ones_like(z2)*dmean2/z2.shape[0]\n",
        "dw2=output1.T@dz2\n",
        "db2=dz2.sum(0,keepdim=True)\n",
        "doutput1=dz2@w2.T\n",
        "\n",
        "dleaky1=(doutput1*mask1)/ (1 - dropout)\n",
        "dbatchout1=torch.where(batchout1>0,1,0.01)*dleaky1\n",
        "dgamma1=(batchnorm1*dbatchout1).sum(0,keepdim=True)\n",
        "dbeta1=dbatchout1.sum(0,keepdim=True)\n",
        "dbatchnorm1=gamma1*dbatchout1\n",
        "dstd1_inv=(diff1*dbatchnorm1).sum(0,keepdim=True)\n",
        "ddiff1=std1_inv*dbatchnorm1\n",
        "dstd1=-1.0*(std1**-2.0)*dstd1_inv\n",
        "ddiff1_sqr_mean=0.5*(diff1_sqr_mean**-0.5)*dstd1\n",
        "ddiff1_sqr=torch.ones_like(diff1_sqr)*ddiff1_sqr_mean/z1.shape[0]\n",
        "ddiff1+=2*diff1*ddiff1_sqr\n",
        "dz1=ddiff1.clone()\n",
        "dmean1=-ddiff1.sum(0,keepdim=True)\n",
        "dz1+=torch.ones_like(z1)*dmean1/z1.shape[0]\n",
        "dw1=x_train.T@dz1\n",
        "db1=dz1.sum(0,keepdim=True)\n",
        "\n",
        "\n",
        "\n",
        "cmp(\"dlogprobs\",dlogprobs,logprobs)\n",
        "cmp(\"dprobs\",dprobs,probs)\n",
        "cmp(\"dexp_sum_inv\",dexp_sum_inv,exp_sum_inv)\n",
        "cmp(\"dexp_sum\",dexp_sum,exp_sum)\n",
        "cmp(\"dexp_z3\",dexp_z3,exp_z3)\n",
        "cmp(\"dnorm_z3\",dnorm_z3,norm_z3)\n",
        "cmp(\"dz3_max\",dz3_max,z3_max)\n",
        "cmp(\"dz3\",dz3,z3)\n",
        "cmp(\"dw3\",dw3,w3)\n",
        "cmp(\"db3\",db3,b3)\n",
        "cmp(\"doutput2\",doutput2,output2)\n",
        "\n",
        "cmp(\"dleaky2\",dleaky2,leaky2)\n",
        "cmp(\"batchout2\",dbatchout2,batchout2)\n",
        "cmp(\"dgamma2\",dgamma2,gamma2)\n",
        "cmp(\"dbeta2\",dbeta2,beta2)\n",
        "cmp(\"dbatchnorm2\",dbatchnorm2,batchnorm2)\n",
        "cmp(\"dstd2_inv\",dstd2_inv,std2_inv)\n",
        "cmp(\"dstd2\",dstd2,std2)\n",
        "cmp(\"ddiff2_sqr_mean\",ddiff2_sqr_mean,diff2_sqr_mean)\n",
        "cmp(\"ddiff2_sqr\",ddiff2_sqr,diff2_sqr)\n",
        "cmp(\"ddiff2\",ddiff2,diff2)\n",
        "cmp(\"dmean2\",dmean2,mean2)\n",
        "cmp(\"dz2\",dz2,z2)\n",
        "cmp(\"doutput1\",doutput1,output1)\n",
        "cmp(\"dw2\",dw2,w2)\n",
        "cmp(\"db2\",db2,b2)\n",
        "\n",
        "cmp(\"dleaky1\",dleaky1,leaky1)\n",
        "cmp(\"dbatchout1\",dbatchout1,batchout1)\n",
        "cmp(\"dgamma1\",dgamma1,gamma1)\n",
        "cmp(\"dbeta1\",dbeta1,beta1)\n",
        "cmp(\"dbatchnorm1\",dbatchnorm1,batchnorm1)\n",
        "cmp(\"dstd1_inv\",dstd1_inv,std1_inv)\n",
        "cmp(\"dstd1\",dstd1,std1)\n",
        "cmp(\"ddiff2_sqr_mean\",ddiff2_sqr_mean,diff2_sqr_mean)\n",
        "cmp(\"ddiff2_sqr\",ddiff2_sqr,diff2_sqr)\n",
        "cmp(\"ddiff1\",ddiff1,diff1)\n",
        "cmp(\"dmean1\",dmean1,mean1)\n",
        "cmp(\"dz1\",dz1,z1)\n",
        "cmp(\"dw1\",dw1,w1)\n",
        "cmp(\"db1\",db1,b1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6peflGt42TZr",
        "outputId": "70aed0c0-b122-42e7-b7d2-ca2ed063a7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogprobs       | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "dprobs          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "dexp_sum_inv    | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "dexp_sum        | exact: False | approximate: True  | maxdiff: 8.731149137020111e-11\n",
            "dexp_z3         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "dnorm_z3        | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "dz3_max         | exact: False | approximate: True  | maxdiff: 7.566995918750763e-10\n",
            "dz3             | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "dw3             | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
            "db3             | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "doutput2        | exact: False | approximate: True  | maxdiff: 2.1827872842550278e-11\n",
            "dleaky2         | exact: False | approximate: True  | maxdiff: 4.3655745685100555e-11\n",
            "batchout2       | exact: False | approximate: True  | maxdiff: 4.3655745685100555e-11\n",
            "dgamma2         | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-10\n",
            "dbeta2          | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-10\n",
            "dbatchnorm2     | exact: False | approximate: True  | maxdiff: 4.3655745685100555e-11\n",
            "dstd2_inv       | exact: False | approximate: True  | maxdiff: 5.820766091346741e-11\n",
            "dstd2           | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
            "ddiff2_sqr_mean | exact: False | approximate: True  | maxdiff: 2.9802322387695312e-08\n",
            "ddiff2_sqr      | exact: False | approximate: True  | maxdiff: 8.731149137020111e-11\n",
            "ddiff2          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "dmean2          | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
            "dz2             | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "doutput1        | exact: False | approximate: True  | maxdiff: 3.637978807091713e-11\n",
            "dw2             | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "db2             | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-09\n",
            "dleaky1         | exact: False | approximate: True  | maxdiff: 5.820766091346741e-11\n",
            "dbatchout1      | exact: False | approximate: True  | maxdiff: 4.3655745685100555e-11\n",
            "dgamma1         | exact: False | approximate: True  | maxdiff: 1.7462298274040222e-10\n",
            "dbeta1          | exact: False | approximate: True  | maxdiff: 2.0372681319713593e-10\n",
            "dbatchnorm1     | exact: False | approximate: True  | maxdiff: 4.3655745685100555e-11\n",
            "dstd1_inv       | exact: False | approximate: True  | maxdiff: 1.0913936421275139e-11\n",
            "dstd1           | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
            "ddiff2_sqr_mean | exact: False | approximate: True  | maxdiff: 2.9802322387695312e-08\n",
            "ddiff2_sqr      | exact: False | approximate: True  | maxdiff: 8.731149137020111e-11\n",
            "ddiff1          | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "dmean1          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "dz1             | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "dw1             | exact: False | approximate: True  | maxdiff: 3.259629011154175e-09\n",
            "db1             | exact: False | approximate: True  | maxdiff: 3.026798367500305e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1=torch.randn(x_train.shape[1],nhidden1)*0.01\n",
        "w1.requires_grad_(False)\n",
        "b1=torch.zeros(1,nhidden1)\n",
        "b1.requires_grad_(False)\n",
        "\n",
        "w2=torch.randn(nhidden1,nhidden2)*0.01\n",
        "w2.requires_grad_(False)\n",
        "b2=torch.zeros(1,nhidden2)\n",
        "b2.requires_grad_(False)\n",
        "\n",
        "w3=torch.randn(nhidden2,noutput)*0.01\n",
        "w3.requires_grad_(False)\n",
        "b3=torch.zeros(1,noutput)\n",
        "b3.requires_grad_(False)\n",
        "\n",
        "\n",
        "gamma1=torch.ones(nhidden1)\n",
        "gamma1.requires_grad_(False)\n",
        "beta1=torch.zeros(nhidden1)\n",
        "beta1.requires_grad_(False)\n",
        "\n",
        "gamma2=torch.ones(nhidden2)\n",
        "gamma2.requires_grad_(False)\n",
        "beta2=torch.zeros(nhidden2)\n",
        "beta2.requires_grad_(False)\n",
        "\n",
        "dropout=0.5\n",
        "alpha=0.01"
      ],
      "metadata": {
        "id": "YTKeDGxDCC8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss=[]\n",
        "val_loss=[]\n",
        "for i in range(100):\n",
        "  batch_loss=[]\n",
        "  for x_train,y_train in train_loader:\n",
        "    x_train=torch.flatten(x_train,2).squeeze(1)\n",
        "    # 1st layer\n",
        "    z1=x_train@w1+b1\n",
        "    # 1st batch normalization\n",
        "    mean1=z1.mean(0,keepdim=True)\n",
        "    diff1=z1-mean1\n",
        "    diff1_sqr=diff1**2.0\n",
        "    diff1_sqr_mean=diff1_sqr.mean(0,keepdim=True)\n",
        "    std1=torch.sqrt(diff1_sqr_mean)\n",
        "    std1_inv=std1**-1.0\n",
        "    batchnorm1=diff1*std1_inv\n",
        "    batchout1=gamma1*batchnorm1+beta1\n",
        "    # 1st activation\n",
        "    leaky1=leaky_relu(batchout1)\n",
        "    # 1st dropout\n",
        "    mask1 = torch.bernoulli(torch.full_like(leaky1, 1 - dropout))\n",
        "    output1 = (mask1 * leaky1) / (1 - dropout)\n",
        "\n",
        "    # 2nd layer\n",
        "    z2=output1@w2+b2\n",
        "    # 2nd batch normalization\n",
        "    mean2=z2.mean(0,keepdim=True)\n",
        "    diff2=z2-mean2\n",
        "    diff2_sqr=diff2**2.0\n",
        "    diff2_sqr_mean=diff2_sqr.mean(0,keepdim=True)\n",
        "    std2=torch.sqrt(diff2_sqr_mean)\n",
        "    std2_inv=std2**-1.0\n",
        "    batchnorm2=diff2*std2_inv\n",
        "    batchout2=gamma2*batchnorm2+beta2\n",
        "    # 2nd activation\n",
        "    leaky2=leaky_relu(batchout2)\n",
        "    # 2nd dropout\n",
        "    mask2 = torch.bernoulli(torch.full_like(leaky2, 1 - dropout))\n",
        "    output2 = (mask2 * leaky2) / (1 - dropout)\n",
        "\n",
        "    # output layer\n",
        "    z3=output2@w3+b3\n",
        "    z3_max=z3.max(1,keepdim=True).values\n",
        "    norm_z3=z3-z3_max\n",
        "    exp_z3=torch.exp(norm_z3)\n",
        "    exp_sum=(exp_z3.sum(dim=1,keepdim=True))\n",
        "    exp_sum_inv=exp_sum**-1\n",
        "    probs=exp_z3*exp_sum_inv\n",
        "    logprobs=torch.log(probs)\n",
        "    loss=-logprobs[range(len(x_train)),y_train].mean()\n",
        "    batch_loss.append(loss.item())\n",
        "\n",
        "    # backpropagation\n",
        "    dlogprobs=torch.zeros_like(logprobs)\n",
        "    dlogprobs[range(len(x_train)),y_train]=-1.0/len(x_train)\n",
        "    dprobs=(1.0/probs)*dlogprobs\n",
        "    dexp_sum_inv=(exp_z3*dprobs).sum(1,keepdim=True)\n",
        "    dexp_z3=exp_sum_inv*dprobs\n",
        "    dexp_sum=(-exp_sum**-2)*dexp_sum_inv\n",
        "    dexp_z3+=torch.ones_like(exp_z3)*dexp_sum\n",
        "    dnorm_z3=torch.exp(norm_z3)*dexp_z3\n",
        "    dz3=dnorm_z3.clone()\n",
        "    dz3_max=(-dnorm_z3).sum(1,keepdim=True)\n",
        "    dz3+=torch.nn.functional.one_hot(z3.max(1).indices,num_classes=z3.shape[1])*dz3_max\n",
        "    dw3=output2.T@dz3\n",
        "    db3=dz3.sum(0,keepdim=True)\n",
        "    doutput2=dz3@w3.T\n",
        "\n",
        "    dleaky2=(doutput2*mask2)/ (1 - dropout)\n",
        "    dbatchout2=torch.where(batchout2>0,1,0.01)*dleaky2\n",
        "    dgamma2=(batchnorm2*dbatchout2).sum(0,keepdim=True)\n",
        "    dbeta2=dbatchout2.sum(0,keepdim=True)\n",
        "    dbatchnorm2=gamma2*dbatchout2\n",
        "    dstd2_inv=(diff2*dbatchnorm2).sum(0,keepdim=True)\n",
        "    ddiff2=std2_inv*dbatchnorm2\n",
        "    dstd2=-1.0*(std2**-2.0)*dstd2_inv\n",
        "    ddiff2_sqr_mean=0.5*(diff2_sqr_mean**-0.5)*dstd2\n",
        "    ddiff2_sqr=torch.ones_like(diff2_sqr)*ddiff2_sqr_mean/z2.shape[0]\n",
        "    ddiff2+=2*diff2*ddiff2_sqr\n",
        "    dz2=ddiff2.clone()\n",
        "    dmean2=-ddiff2.sum(0,keepdim=True)\n",
        "    dz2+=torch.ones_like(z2)*dmean2/z2.shape[0]\n",
        "    dw2=output1.T@dz2\n",
        "    db2=dz2.sum(0,keepdim=True)\n",
        "    doutput1=dz2@w2.T\n",
        "\n",
        "    dleaky1=(doutput1*mask1)/ (1 - dropout)\n",
        "    dbatchout1=torch.where(batchout1>0,1,0.01)*dleaky1\n",
        "    dgamma1=(batchnorm1*dbatchout1).sum(0,keepdim=True)\n",
        "    dbeta1=dbatchout1.sum(0,keepdim=True)\n",
        "    dbatchnorm1=gamma1*dbatchout1\n",
        "    dstd1_inv=(diff1*dbatchnorm1).sum(0,keepdim=True)\n",
        "    ddiff1=std1_inv*dbatchnorm1\n",
        "    dstd1=-1.0*(std1**-2.0)*dstd1_inv\n",
        "    ddiff1_sqr_mean=0.5*(diff1_sqr_mean**-0.5)*dstd1\n",
        "    ddiff1_sqr=torch.ones_like(diff1_sqr)*ddiff1_sqr_mean/z1.shape[0]\n",
        "    ddiff1+=2*diff1*ddiff1_sqr\n",
        "    dz1=ddiff1.clone()\n",
        "    dmean1=-ddiff1.sum(0,keepdim=True)\n",
        "    dz1+=torch.ones_like(z1)*dmean1/z1.shape[0]\n",
        "    dw1=x_train.T@dz1\n",
        "    db1=dz1.sum(0,keepdim=True)\n",
        "\n",
        "    w3-=alpha*dw3\n",
        "    b3-=alpha*db3\n",
        "    w2-=alpha*dw2\n",
        "    b2-=alpha*db2\n",
        "    w1-=alpha*dw1\n",
        "    b1-=alpha*db1\n",
        "    gamma1-=alpha*dgamma1.squeeze(0)\n",
        "    beta1-=alpha*dbeta1.squeeze(0)\n",
        "    gamma2-=alpha*dgamma2.squeeze(0)\n",
        "    beta2-=alpha*dbeta2.squeeze(0)\n",
        "\n",
        "\n",
        "  batchval_loss=[]\n",
        "  for x_train,y_train in val_loader:\n",
        "    x_train=torch.flatten(x_train,2).squeeze(1)\n",
        "    # 1st layer\n",
        "    z1=x_train@w1+b1\n",
        "    # 1st batch normalization\n",
        "    mean1=z1.mean(0,keepdim=True)\n",
        "    diff1=z1-mean1\n",
        "    diff1_sqr=diff1**2.0\n",
        "    diff1_sqr_mean=diff1_sqr.mean(0,keepdim=True)\n",
        "    std1=torch.sqrt(diff1_sqr_mean)\n",
        "    std1_inv=std1**-1.0\n",
        "    batchnorm1=diff1*std1_inv\n",
        "    batchout1=gamma1*batchnorm1+beta1\n",
        "    # 1st activation\n",
        "    leaky1=leaky_relu(batchout1)\n",
        "\n",
        "    # 2nd layer\n",
        "    z2=leaky1@w2+b2\n",
        "    # 2nd batch normalization\n",
        "    mean2=z2.mean(0,keepdim=True)\n",
        "    diff2=z2-mean2\n",
        "    diff2_sqr=diff2**2.0\n",
        "    diff2_sqr_mean=diff2_sqr.mean(0,keepdim=True)\n",
        "    std2=torch.sqrt(diff2_sqr_mean)\n",
        "    std2_inv=std2**-1.0\n",
        "    batchnorm2=diff2*std2_inv\n",
        "    batchout2=gamma2*batchnorm2+beta2\n",
        "    # 2nd activation\n",
        "    leaky2=leaky_relu(batchout2)\n",
        "\n",
        "    # output layer\n",
        "    z3=leaky2@w3+b3\n",
        "    z3_max=z3.max(1,keepdim=True).values\n",
        "    norm_z3=z3-z3_max\n",
        "    exp_z3=torch.exp(norm_z3)\n",
        "    exp_sum=(exp_z3.sum(dim=1,keepdim=True))\n",
        "    exp_sum_inv=exp_sum**-1\n",
        "    probs=exp_z3*exp_sum_inv\n",
        "    logprobs=torch.log(probs)\n",
        "    valloss=-logprobs[range(len(x_train)),y_train].mean()\n",
        "    batchval_loss.append(valloss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  train_loss.append(sum(batch_loss)/len(batch_loss))\n",
        "  val_loss.append(sum(batchval_loss)/len(batchval_loss))\n",
        "  print(f\"Epoch={i}\\tTrain Loss={sum(batch_loss)/len(batch_loss)}\\tVal Loss={sum(batchval_loss)/len(batchval_loss)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXCMGiXfCL1i",
        "outputId": "b0dde454-6fa3-475d-aeff-3d2a4b55e3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=0\tTrain Loss=1.7900314874947072\tVal Loss=1.1069045543670655\n",
            "Epoch=1\tTrain Loss=1.0369170468300581\tVal Loss=0.6436121582984924\n",
            "Epoch=2\tTrain Loss=0.7616625912487507\tVal Loss=0.44541619122028353\n",
            "Epoch=3\tTrain Loss=0.634169852361083\tVal Loss=0.3529269263148308\n",
            "Epoch=4\tTrain Loss=0.5579985810443759\tVal Loss=0.30033216811716557\n",
            "Epoch=5\tTrain Loss=0.5117682026699185\tVal Loss=0.2661301355808973\n",
            "Epoch=6\tTrain Loss=0.474845671467483\tVal Loss=0.24193980172276497\n",
            "Epoch=7\tTrain Loss=0.4515694472938776\tVal Loss=0.22464093901216983\n",
            "Epoch=8\tTrain Loss=0.42987310905009507\tVal Loss=0.20960286930203437\n",
            "Epoch=9\tTrain Loss=0.4172543426975608\tVal Loss=0.2001475278288126\n",
            "Epoch=10\tTrain Loss=0.4010187014937401\tVal Loss=0.18919690251350402\n",
            "Epoch=11\tTrain Loss=0.38466446436941626\tVal Loss=0.17846618890762328\n",
            "Epoch=12\tTrain Loss=0.3786217836663127\tVal Loss=0.1735999934375286\n",
            "Epoch=13\tTrain Loss=0.364385899528861\tVal Loss=0.16671173200011252\n",
            "Epoch=14\tTrain Loss=0.3577164413407445\tVal Loss=0.16206790823489428\n",
            "Epoch=15\tTrain Loss=0.3505247486755252\tVal Loss=0.15902191456407308\n",
            "Epoch=16\tTrain Loss=0.34247222179546954\tVal Loss=0.15408114511519672\n",
            "Epoch=17\tTrain Loss=0.3402721742168069\tVal Loss=0.1491473414003849\n",
            "Epoch=18\tTrain Loss=0.33254210110753774\tVal Loss=0.14682280234992504\n",
            "Epoch=19\tTrain Loss=0.32272623023018243\tVal Loss=0.14463131166994572\n",
            "Epoch=20\tTrain Loss=0.31745330793783066\tVal Loss=0.14132852386683226\n",
            "Epoch=21\tTrain Loss=0.31700944546610116\tVal Loss=0.13956004083156587\n",
            "Epoch=22\tTrain Loss=0.3108010169118643\tVal Loss=0.13804573845118284\n",
            "Epoch=23\tTrain Loss=0.30576936872676014\tVal Loss=0.13349282145500183\n",
            "Epoch=24\tTrain Loss=0.2978494938462973\tVal Loss=0.1325622683390975\n",
            "Epoch=25\tTrain Loss=0.29541716668754814\tVal Loss=0.12931357976049185\n",
            "Epoch=26\tTrain Loss=0.2888444796204567\tVal Loss=0.12746261935681105\n",
            "Epoch=27\tTrain Loss=0.2953165148384869\tVal Loss=0.12757732383906842\n",
            "Epoch=28\tTrain Loss=0.28258847231045364\tVal Loss=0.12476053889840841\n",
            "Epoch=29\tTrain Loss=0.2811833913438022\tVal Loss=0.12395679857581854\n",
            "Epoch=30\tTrain Loss=0.2799983025528491\tVal Loss=0.12381213624030352\n",
            "Epoch=31\tTrain Loss=0.2818894454278052\tVal Loss=0.12379168979823589\n",
            "Epoch=32\tTrain Loss=0.2765777208842337\tVal Loss=0.12229924518615007\n",
            "Epoch=33\tTrain Loss=0.2807613273151219\tVal Loss=0.11894233524799347\n",
            "Epoch=34\tTrain Loss=0.269569703284651\tVal Loss=0.11989985667169094\n",
            "Epoch=35\tTrain Loss=0.265603955835104\tVal Loss=0.11945858877152205\n",
            "Epoch=36\tTrain Loss=0.27042973320931196\tVal Loss=0.11809055618941784\n",
            "Epoch=37\tTrain Loss=0.2622943722642958\tVal Loss=0.11734022982418538\n",
            "Epoch=38\tTrain Loss=0.2612484795972705\tVal Loss=0.11808229330927134\n",
            "Epoch=39\tTrain Loss=0.25428955601528286\tVal Loss=0.11614439971745014\n",
            "Epoch=40\tTrain Loss=0.2578998926095665\tVal Loss=0.1147843562066555\n",
            "Epoch=41\tTrain Loss=0.25748062832280993\tVal Loss=0.11473312936723232\n",
            "Epoch=42\tTrain Loss=0.25149228936061263\tVal Loss=0.11241505704820157\n",
            "Epoch=43\tTrain Loss=0.25737515594810245\tVal Loss=0.11300289509817958\n",
            "Epoch=44\tTrain Loss=0.24997691698372365\tVal Loss=0.11163931051269174\n",
            "Epoch=45\tTrain Loss=0.24271617662161588\tVal Loss=0.11094622584059835\n",
            "Epoch=46\tTrain Loss=0.2483622904866934\tVal Loss=0.11015389179810882\n",
            "Epoch=47\tTrain Loss=0.24996896805241703\tVal Loss=0.11012740917503834\n",
            "Epoch=48\tTrain Loss=0.23939732694998384\tVal Loss=0.10992062371224165\n",
            "Epoch=49\tTrain Loss=0.24548099851235747\tVal Loss=0.10939285084605217\n",
            "Epoch=50\tTrain Loss=0.2379705999046564\tVal Loss=0.10941783916205168\n",
            "Epoch=51\tTrain Loss=0.24050717120990156\tVal Loss=0.10923530338332058\n",
            "Epoch=52\tTrain Loss=0.23520423537120222\tVal Loss=0.10618248768150806\n",
            "Epoch=53\tTrain Loss=0.2347507811151445\tVal Loss=0.10616660537198186\n",
            "Epoch=54\tTrain Loss=0.23434738125652074\tVal Loss=0.10549980672076345\n",
            "Epoch=55\tTrain Loss=0.22796695753932\tVal Loss=0.10594352772459388\n",
            "Epoch=56\tTrain Loss=0.2289343575015664\tVal Loss=0.10511983931064606\n",
            "Epoch=57\tTrain Loss=0.230093739554286\tVal Loss=0.1031818363815546\n",
            "Epoch=58\tTrain Loss=0.22969387071207165\tVal Loss=0.10462743584066629\n",
            "Epoch=59\tTrain Loss=0.22612501927651465\tVal Loss=0.105841348413378\n",
            "Epoch=60\tTrain Loss=0.2261271957308054\tVal Loss=0.10540081383660435\n",
            "Epoch=61\tTrain Loss=0.22373973308131098\tVal Loss=0.10409887721762061\n",
            "Epoch=62\tTrain Loss=0.22674285816028714\tVal Loss=0.10346657801419497\n",
            "Epoch=63\tTrain Loss=0.22470196089707314\tVal Loss=0.10221904199570417\n",
            "Epoch=64\tTrain Loss=0.22069076392799616\tVal Loss=0.10290242498740554\n",
            "Epoch=65\tTrain Loss=0.2237966545391828\tVal Loss=0.10127817234024405\n",
            "Epoch=66\tTrain Loss=0.22024535997770728\tVal Loss=0.10013453848659992\n",
            "Epoch=67\tTrain Loss=0.21881824266165495\tVal Loss=0.10074596907943487\n",
            "Epoch=68\tTrain Loss=0.2210332273505628\tVal Loss=0.10078339092433453\n",
            "Epoch=69\tTrain Loss=0.21483967304229737\tVal Loss=0.10073216836899519\n",
            "Epoch=70\tTrain Loss=0.21512642800807952\tVal Loss=0.10033170953392982\n",
            "Epoch=71\tTrain Loss=0.2169214184395969\tVal Loss=0.10021785805001855\n",
            "Epoch=72\tTrain Loss=0.21750234393402934\tVal Loss=0.1006464995443821\n",
            "Epoch=73\tTrain Loss=0.20993961030617356\tVal Loss=0.10046324133872986\n",
            "Epoch=74\tTrain Loss=0.2150165013037622\tVal Loss=0.09761248650029301\n",
            "Epoch=75\tTrain Loss=0.21042617578059436\tVal Loss=0.09785648453980685\n",
            "Epoch=76\tTrain Loss=0.20664087175391616\tVal Loss=0.09923470122739672\n",
            "Epoch=77\tTrain Loss=0.2091953855007887\tVal Loss=0.09793352158740162\n",
            "Epoch=78\tTrain Loss=0.20929892887361348\tVal Loss=0.09925490655004979\n",
            "Epoch=79\tTrain Loss=0.21058137719519437\tVal Loss=0.09791754642501474\n",
            "Epoch=80\tTrain Loss=0.20487382048740982\tVal Loss=0.09590559359639883\n",
            "Epoch=81\tTrain Loss=0.20653680274263025\tVal Loss=0.09674641527235509\n",
            "Epoch=82\tTrain Loss=0.20094127324409783\tVal Loss=0.0962315795943141\n",
            "Epoch=83\tTrain Loss=0.19997049104422332\tVal Loss=0.0969158098101616\n",
            "Epoch=84\tTrain Loss=0.2059623161330819\tVal Loss=0.09714255863800644\n",
            "Epoch=85\tTrain Loss=0.2006605145521462\tVal Loss=0.09709950499236583\n",
            "Epoch=86\tTrain Loss=0.20570833748206496\tVal Loss=0.09572706120088696\n",
            "Epoch=87\tTrain Loss=0.19858910739421845\tVal Loss=0.09478643145412206\n",
            "Epoch=88\tTrain Loss=0.20255915229208768\tVal Loss=0.09512267131358385\n",
            "Epoch=89\tTrain Loss=0.20043599903583526\tVal Loss=0.0953510409221053\n",
            "Epoch=90\tTrain Loss=0.19958005910739302\tVal Loss=0.09461724953725933\n",
            "Epoch=91\tTrain Loss=0.19287047097459437\tVal Loss=0.09367269277572632\n",
            "Epoch=92\tTrain Loss=0.19631585590541362\tVal Loss=0.09366886634379626\n",
            "Epoch=93\tTrain Loss=0.19616313693113624\tVal Loss=0.09550698287785053\n",
            "Epoch=94\tTrain Loss=0.19517811955884098\tVal Loss=0.09506093747913838\n",
            "Epoch=95\tTrain Loss=0.1961256609298289\tVal Loss=0.0936483258381486\n",
            "Epoch=96\tTrain Loss=0.19509582608006895\tVal Loss=0.09472842775285244\n",
            "Epoch=97\tTrain Loss=0.19549479042179882\tVal Loss=0.09346557222306728\n",
            "Epoch=98\tTrain Loss=0.19048435022123159\tVal Loss=0.09549151882529258\n",
            "Epoch=99\tTrain Loss=0.19222023598849775\tVal Loss=0.09455883419141173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss,label=\"Train Loss\")\n",
        "plt.plot(val_loss,label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "mBEociTxD1na",
        "outputId": "bec1e2f9-1d34-4b29-e3b0-91e8d1b74c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for x_test, y_test in test_loader:\n",
        "  x_test = torch.flatten(x_test, 2).squeeze(1)\n",
        "  # 1st layer\n",
        "  z1=x_test@w1+b1\n",
        "  # 1st batch normalization\n",
        "  mean1=z1.mean(0,keepdim=True)\n",
        "  diff1=z1-mean1\n",
        "  diff1_sqr=diff1**2.0\n",
        "  diff1_sqr_mean=diff1_sqr.mean(0,keepdim=True)\n",
        "  std1=torch.sqrt(diff1_sqr_mean)\n",
        "  std1_inv=std1**-1.0\n",
        "  batchnorm1=diff1*std1_inv\n",
        "  batchout1=gamma1*batchnorm1+beta1\n",
        "  # 1st activation\n",
        "  leaky1=leaky_relu(batchout1)\n",
        "\n",
        "  # 2nd layer\n",
        "  z2=leaky1@w2+b2\n",
        "  # 2nd batch normalization\n",
        "  mean2=z2.mean(0,keepdim=True)\n",
        "  diff2=z2-mean2\n",
        "  diff2_sqr=diff2**2.0\n",
        "  diff2_sqr_mean=diff2_sqr.mean(0,keepdim=True)\n",
        "  std2=torch.sqrt(diff2_sqr_mean)\n",
        "  std2_inv=std2**-1.0\n",
        "  batchnorm2=diff2*std2_inv\n",
        "  batchout2=gamma2*batchnorm2+beta2\n",
        "  # 2nd activation\n",
        "  leaky2=leaky_relu(batchout2)\n",
        "\n",
        "  # output layer\n",
        "  z3=leaky2@w3+b3\n",
        "  z3_max=z3.max(1,keepdim=True).values\n",
        "  norm_z3=z3-z3_max\n",
        "  exp_z3=torch.exp(norm_z3)\n",
        "  probs = exp_z3 / exp_z3.sum(dim=1, keepdim=True)\n",
        "\n",
        "  # Predictions\n",
        "  predictions = torch.argmax(probs, dim=1)\n",
        "  correct += (predictions == y_test).sum().item()\n",
        "  total += y_test.size(0)\n",
        "\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGGdcKe7FU6c",
        "outputId": "75bd4844-ae27-4acd-842c-f562d28eb32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.23%\n"
          ]
        }
      ]
    }
  ]
}