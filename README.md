# ANN
Develop a simple Artificial Neural Network (ANN) with two hidden layers, implementing from scratch features such as batch normalization, Leaky ReLU activation, softmax, cross-entropy loss, and dropout. Manually compute gradients and compare them with gradients obtained using autograd. Train the model on the MNIST dataset.
